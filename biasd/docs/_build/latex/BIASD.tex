% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}

\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
\else\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}
\usepackage{eqparbox}


\addto\captionsenglish{\renewcommand{\figurename}{Fig. }}
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\SetupFloatingEnvironment{literal-block}{name=Listing }

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{1}


\title{BIASD Documentation}
\date{Jun 17, 2016}
\release{0.1}
\author{Colin Kinz-Thompson}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}



\chapter{BIASD}
\label{index:bayesian-inference-for-the-analysis-of-sub-temporal-resolution-data}\label{index:biasd}
BIASD allows you to analyze Markovian signal versus time series, such as those collected in single-molecule biophysics experiments, even when the kinetics of the underlying Markov chain are faster than the signal acquisition rate. The code here has been written in python for easy implementation, but unfortunately, the likelihood function is computationally expensive since it involves a numerical integral. Therefore, the likelihood function is also provided as C code and also in CUDA with python wrappers to use them with the rest of the code base.


\chapter{Contents:}
\label{index:contents}

\section{Getting Started}
\label{getstarted:getstarted}\label{getstarted:getting-started}\label{getstarted::doc}
Here're some quick examples to get you started using BIASD. In general, BIASD uses the SMD data format (DOI: 10.1186/s12859-014-0429-4) for data storage, though this is not required. It also uses \titleref{emcee} (arXiv:1202.3665) to perform the Markov chain Monte Carlo (MCMC), though the Laplace approximation is also provided, which does not use emcee.

You can install \code{emcee} with

\begin{Verbatim}[commandchars=\\\{\}]
pip install emcee
\end{Verbatim}

You might also want to get \code{corner} for plotting purposes. Use

\begin{Verbatim}[commandchars=\\\{\}]
pip install corner
\end{Verbatim}


\subsection{BIASD + MCMC}
\label{getstarted:biasd-mcmc}
BIASD uses \titleref{emcee}, which is a seriously awesome, affine invariant Markov chain Monte Carlo sample. Read about it \href{http://dan.iel.fm/emcee/current/}{here}.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{biasd} \PYG{k+kn}{as} \PYG{n+nn}{b}

\PYG{c}{\PYGZsh{} Load some SMD format data}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{data.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Setup prior distributions}
\PYG{n}{e1} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{beta}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mf}{9.}\PYG{p}{)}
\PYG{n}{e2} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{beta}\PYG{p}{(}\PYG{l+m+mf}{9.2}\PYG{p}{,}\PYG{o}{.}\PYG{l+m+mi}{8}\PYG{p}{)}
\PYG{n}{sigma} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{gamma}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{,}\PYG{l+m+mf}{1.}\PYG{o}{/}\PYG{l+m+mf}{4.8}\PYG{p}{)}
\PYG{n}{k1} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{gamma}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{,}\PYG{l+m+mf}{1.}\PYG{o}{/}\PYG{l+m+mi}{3}\PYG{p}{)}
\PYG{n}{k2} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{gamma}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{,}\PYG{l+m+mf}{1.}\PYG{o}{/}\PYG{l+m+mf}{8.}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Collect the distributions}
\PYG{n}{priors} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{parameter\PYGZus{}collection}\PYG{p}{(}\PYG{n}{e1}\PYG{p}{,}\PYG{n}{e2}\PYG{p}{,}\PYG{n}{sigma}\PYG{p}{,}\PYG{n}{k1}\PYG{p}{,}\PYG{n}{k2}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Loop over all the traces}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{data}\PYG{o}{.}\PYG{n}{attr}\PYG{o}{.}\PYG{n}{n\PYGZus{}traces}\PYG{p}{)}\PYG{p}{:}

        \PYG{c}{\PYGZsh{} Log the priors for this molecule in the SMD}
        \PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{add}\PYG{o}{.}\PYG{n}{priors}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{n}{i}\PYG{p}{,}\PYG{n}{priors}\PYG{p}{)}

        \PYG{c}{\PYGZsh{} Setup the MCMC sampler with 50 walkers and 8 CPUs on the FRET data}
        \PYG{n}{nwalkers} \PYG{o}{=} \PYG{l+m+mi}{50}
        \PYG{n}{sampler}\PYG{p}{,} \PYG{n}{initial\PYGZus{}positions} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{setup}\PYG{p}{(}\PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{o}{.}\PYG{n}{values}\PYG{o}{.}\PYG{n}{FRET}\PYG{p}{,}
                \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{priors}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{n}{i}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tau}\PYG{p}{,}
                \PYG{n}{nwalkers}\PYG{p}{,} \PYG{n}{initialize}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{rvs}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{threads}\PYG{o}{=}\PYG{l+m+mi}{8}\PYG{p}{)}

        \PYG{c}{\PYGZsh{} Run the MCMC: burn\PYGZhy{}in first, then production}
        \PYG{n}{sampler}\PYG{p}{,} \PYG{n}{burned\PYGZus{}positions} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{burn\PYGZus{}in}\PYG{p}{(}\PYG{n}{sampler}\PYG{p}{,}
                \PYG{n}{initial\PYGZus{}positions}\PYG{p}{,} \PYG{n}{nsteps}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{)}
        \PYG{n}{sampler} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{run}\PYG{p}{(}\PYG{n}{sampler}\PYG{p}{,}\PYG{n}{burned\PYGZus{}positions}\PYG{p}{,}\PYG{n}{nsteps}\PYG{o}{=}\PYG{l+m+mi}{1000}\PYG{p}{,}\PYG{n}{timer}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}

        \PYG{c}{\PYGZsh{} Calculate acceptance ratio and autocorrelation times}
        \PYG{n}{largest\PYGZus{}autocorrelation\PYGZus{}time} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{chain\PYGZus{}statistics}\PYG{p}{(}\PYG{n}{sampler}\PYG{p}{)}

        \PYG{c}{\PYGZsh{} Save this data}
        \PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{add}\PYG{o}{.}\PYG{n}{mcmc}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{n}{i}\PYG{p}{,}\PYG{n}{sampler}\PYG{p}{)}
        \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{save}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{data.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{data}\PYG{p}{)}
\end{Verbatim}


\subsection{Plot BIASD-MCMC Results Using Corner}
\label{getstarted:plot-biasd-mcmc-results-using-corner}
Use corner to plot the 5-D space of the posterior sampled by MCMC. Read about corner \href{http://corner.readthedocs.io/en/latest/}{here}.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{biasd} \PYG{k+kn}{as} \PYG{n+nn}{b}

\PYG{c}{\PYGZsh{} Load some SMD format data}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{data.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Get read the sampler results for the first trace (0)}
\PYG{n}{sampler\PYGZus{}results} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{read}\PYG{o}{.}\PYG{n}{mcmc}\PYG{p}{(}\PYG{n}{s}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Get the correlated samples}
\PYG{n}{samples\PYGZus{}corr} \PYG{o}{=} \PYG{n}{sampler\PYGZus{}results}\PYG{o}{.}\PYG{n}{chain}

\PYG{c}{\PYGZsh{} Remove some really bad samples}
\PYG{n}{cut} \PYG{o}{=} \PYG{n}{sampler\PYGZus{}results}\PYG{o}{.}\PYG{n}{lnprobability} \PYG{o}{\PYGZlt{}} \PYG{l+m+mf}{0.}
\PYG{n}{samples\PYGZus{}corr} \PYG{o}{=} \PYG{n}{samples\PYGZus{}corr}\PYG{p}{[}\PYG{o}{\PYGZti{}}\PYG{n}{cut}\PYG{p}{]}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{5}\PYG{p}{)}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Get the uncorrelated samples (previously calculated)}
\PYG{n}{samples\PYGZus{}uncorr} \PYG{o}{=} \PYG{n}{sampler\PYGZus{}results}\PYG{o}{.}\PYG{n}{samples}

\PYG{c}{\PYGZsh{} Plot corner plots}
\PYG{n}{f} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{plot\PYGZus{}corner}\PYG{p}{(}\PYG{n}{samples\PYGZus{}corr}\PYG{p}{)}
\PYG{n}{f} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{plot\PYGZus{}corner}\PYG{p}{(}\PYG{n}{samples\PYGZus{}uncorr}\PYG{p}{)}
\end{Verbatim}


\subsection{Plot BIASD-MCMC Results Using Viewer}
\label{getstarted:plot-biasd-mcmc-results-using-viewer}
From the above example with corner, you can use the built in distribution viewer to explore the marginalized BIASD posterior distribution.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{} Create a collection of distributions from the marginalized samples}
\PYG{n}{posterior} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{create\PYGZus{}posterior\PYGZus{}collection}\PYG{p}{(}\PYG{n}{samples\PYGZus{}uncorr}\PYG{p}{,}\PYG{n}{priors}\PYG{p}{)}

\PYG{c}{\PYGZsh{} View the marginalized posterior in a biasd.distribution.viewer}
\PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{viewer}\PYG{p}{(}\PYG{n}{posterior}\PYG{p}{)}
\end{Verbatim}


\subsection{BIASD + Laplace Approximation}
\label{getstarted:biasd-laplace-approximation}
You can also use the Laplace approximation to approximate the posterior distribution as a multidimensional gaussian centered the the maximum a postiori (MAP) value of the distribution. The advantage is that it is probably faster than MCMC, however, it is definitely an approximation.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{biasd} \PYG{k+kn}{as} \PYG{n+nn}{b}

\PYG{c}{\PYGZsh{} Load some SMD format data}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{data.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{tau} \PYG{o}{=} \PYG{l+m+mf}{0.1}

\PYG{c}{\PYGZsh{} Setup the prior distributions}
\PYG{n}{e1} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{beta}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{,}\PYG{l+m+mf}{9.}\PYG{p}{)}
\PYG{n}{e2} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{beta}\PYG{p}{(}\PYG{l+m+mf}{9.}\PYG{p}{,}\PYG{l+m+mf}{1.}\PYG{p}{)}
\PYG{n}{sigma} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{gamma}\PYG{p}{(}\PYG{l+m+mf}{2.}\PYG{p}{,}\PYG{l+m+mf}{2.}\PYG{o}{/}\PYG{o}{.}\PYG{l+m+mo}{05}\PYG{p}{)}
\PYG{n}{k1} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{gamma}\PYG{p}{(}\PYG{l+m+mf}{20.}\PYG{p}{,}\PYG{l+m+mf}{20.}\PYG{o}{/}\PYG{l+m+mf}{3.}\PYG{p}{)}
\PYG{n}{k2} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{gamma}\PYG{p}{(}\PYG{l+m+mf}{20.}\PYG{p}{,}\PYG{l+m+mf}{20.}\PYG{o}{/}\PYG{l+m+mf}{8.}\PYG{p}{)}
\PYG{n}{priors} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{parameter\PYGZus{}collection}\PYG{p}{(}\PYG{n}{e1}\PYG{p}{,}\PYG{n}{e2}\PYG{p}{,}\PYG{n}{sigma}\PYG{p}{,}\PYG{n}{k1}\PYG{p}{,}\PYG{n}{k2}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Loop over the traces}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{data}\PYG{o}{.}\PYG{n}{attr}\PYG{o}{.}\PYG{n}{n\PYGZus{}traces}\PYG{p}{)}\PYG{p}{:}

        \PYG{c}{\PYGZsh{} Perform Laplace approximation}
        \PYG{n}{d} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{o}{.}\PYG{n}{values}\PYG{o}{.}\PYG{n}{FRET}
        \PYG{n}{lp} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{laplace}\PYG{o}{.}\PYG{n}{laplace\PYGZus{}approximation}\PYG{p}{(}\PYG{n}{d}\PYG{p}{,}\PYG{n}{priors}\PYG{p}{,}\PYG{n}{tau}\PYG{p}{)}

        \PYG{c}{\PYGZsh{} Add the priors and results to the SMD}
        \PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{add}\PYG{o}{.}\PYG{n}{priors}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{n}{i}\PYG{p}{,}\PYG{n}{priors}\PYG{p}{)}
        \PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{add}\PYG{o}{.}\PYG{n}{laplace\PYGZus{}posterior}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{n}{i}\PYG{p}{,}\PYG{n}{lp}\PYG{p}{)}

        \PYG{c}{\PYGZsh{} Calculate the moment\PYGZhy{}matched, marginalized posterior}
        \PYG{c}{\PYGZsh{} of the same form as the prior distributions}
        \PYG{n}{lp}\PYG{o}{.}\PYG{n}{transform}\PYG{p}{(}\PYG{n}{priors}\PYG{p}{)}
        \PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{add}\PYG{o}{.}\PYG{n}{posterior}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{n}{i}\PYG{p}{,}\PYG{n}{lp}\PYG{o}{.}\PYG{n}{posterior}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Save the results}
\PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{save}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{data.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{data}\PYG{p}{)}
\end{Verbatim}


\subsection{My Baseline and BIASD...}
\label{getstarted:my-baseline-and-biasd}
If your baseline is crazy, BIASD will not work very well. In the \code{./utils} directory there a method to try to integrate out a baseline that follows a Brownian diffusion process. Since this implementation is built upon a Gaussian mixture model, it's probably inappropriate to use this when there is a lot of blurring.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{} Load data}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{data.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Let\PYGZsq{}s remove the baseline of the first trace}
\PYG{n}{d} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{values}\PYG{o}{.}\PYG{n}{FRET}
\PYG{n}{baseline\PYGZus{}result} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{baseline}\PYG{o}{.}\PYG{n}{remove\PYGZus{}baseline}\PYG{p}{(}\PYG{n}{d}\PYG{p}{)}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{add}\PYG{o}{.}\PYG{n}{baseline}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{baseline\PYGZus{}result}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Save the results}
\PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{save}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{data.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{data}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Subtract off the baseline for use in some other calculation}
\PYG{n}{d} \PYG{o}{\PYGZhy{}}\PYG{o}{=} \PYG{n}{baseline\PYGZus{}result}\PYG{o}{.}\PYG{n}{baseline}
\end{Verbatim}


\section{Compiling the Likelihood}
\label{compileguide:compiling-the-likelihood}\label{compileguide::doc}\label{compileguide:compileguide}

\subsection{Background}
\label{compileguide:background}
The BIASD log-likelihood function is something like
\begin{align*}\begin{aligned}
\begin{split}ln(\mathcal{L}) \sim \sum\limits_t ln \left( \delta(f) + \delta(1-f) + \int\limits_0^1 df \cdot \rm{blurring} \right)\end{split}\end{aligned}\end{align*}
Unfortunately, the integral in the logarithm makes it difficult to compute. It is the rate limiting step for this calculation, which is quite slow in Python. Therefore, this package comes with the log-likelihood function written in  C, and also in CUDA. There are three versions in the \code{./src} directory. One is in pure C -- it should be fairly straight forward to compile. The second is written in C with the \href{https://www.gnu.org/software/gsl/}{GNU Science Library (GSL)} -- it's slightly faster, but requires having installed GSL. The third is in CUDA, which allows the calculations to be performed on NVIDIA GPUs. You can use any of the above if compiled, or a version written in Python if you don't want to compile anything.


\subsection{How to Compile}
\label{compileguide:how-to-compile}
There's a Makefile included in the package that will allow you to easily compile all of the libraries necessary to calculate BIASD likelihoods. First, to download GSL, go to their \href{ftp://ftp.gnu.org/gnu/gsl/}{FTP site} and download the latest version. Un-pack it, then in the terminal, navigate to the directory using \code{cd} and type

\begin{Verbatim}[commandchars=\\\{\}]
./configure
make
make install
\end{Verbatim}

Now, even if you didn't install GSL, you can compile the BIASD likelihood functions. In the terminal, move to the BIASD directory using \code{cd}, and make them with

\begin{Verbatim}[commandchars=\\\{\}]
make
\end{Verbatim}

Some might fail, for instance if you don't have a CUDA-enabled GPU, but you'll compile as many as possible into the \code{./lib} directory.


\subsection{Testing Speed}
\label{compileguide:testing-speed}
To get a feeling for how long it takes the various versions of the BIASD likelihood function to execute, you can use the test function in the likelihood module. For instance, try

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{biasd}

\PYG{c}{\PYGZsh{} Switch to the Python version}
\PYG{n}{biasd}\PYG{o}{.}\PYG{n}{likelihood}\PYG{o}{.}\PYG{n}{use\PYGZus{}python\PYGZus{}ll}\PYG{p}{(}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Run the test 10 times, for 5000 datapoints}
\PYG{n}{biasd}\PYG{o}{.}\PYG{n}{likelihood}\PYG{o}{.}\PYG{n}{test\PYGZus{}speed}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{5000}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Switch to the C version and test}
\PYG{c}{\PYGZsh{} Note: will default to GSL over pure C}
\PYG{n}{biasd}\PYG{o}{.}\PYG{n}{likelihood}\PYG{o}{.}\PYG{n}{use\PYGZus{}C\PYGZus{}ll}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{biasd}\PYG{o}{.}\PYG{n}{likelihood}\PYG{o}{.}\PYG{n}{test\PYGZus{}speed}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{5000}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Switch to the CUDA version and test}
\PYG{n}{biasd}\PYG{o}{.}\PYG{n}{likelihood}\PYG{o}{.}\PYG{n}{use\PYGZus{}CUDA\PYGZus{}ll}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{biasd}\PYG{o}{.}\PYG{n}{likelihood}\PYG{o}{.}\PYG{n}{test\PYGZus{}speed}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{5000}\PYG{p}{)}
\end{Verbatim}

The actual execution time depends upon the rate constants, but Python is \textasciitilde{} 1 ms, C with GSL is around \textasciitilde{}40 us, and CUDA (when you have many datapoints) is \textasciitilde{} 5 us.


\chapter{Code Documentation:}
\label{index:code-documentation}

\section{Distributions}
\label{code_distributions:distributions}\label{code_distributions:code-distributions}\label{code_distributions::doc}
This page gives the details about the code in biasd.distributions.


\subsection{Some standard probability distributions}
\label{code_distributions:some-standard-probability-distributions}\label{code_distributions:module-distributions}\index{distributions (module)}\index{beta (class in distributions)}

\begin{fulllineitems}
\phantomsection\label{code_distributions:distributions.beta}\pysiglinewithargsret{\strong{class }\code{distributions.}\bfcode{beta}}{\emph{alpha}, \emph{beta}}{}
The beta distribution is often used for probabilities or fractions.

It is \(p(x\vert\alpha ,\beta) = \frac{ x^{\alpha-1}(1-x)^{\beta-1}}{B(\alpha ,\beta)}\)

\end{fulllineitems}

\index{gamma (class in distributions)}

\begin{fulllineitems}
\phantomsection\label{code_distributions:distributions.gamma}\pysiglinewithargsret{\strong{class }\code{distributions.}\bfcode{gamma}}{\emph{alpha}, \emph{beta}}{}
The gamma distribution is often used for compounded times.

It is \(p(x\vert\alpha ,\beta) = \frac{ \beta^\alpha x^{\alpha - 1} e^{-\beta x} }{\Gamma(\alpha)}\)

Parameters are alpha (shape), and beta (rate)

\end{fulllineitems}

\index{normal (class in distributions)}

\begin{fulllineitems}
\phantomsection\label{code_distributions:distributions.normal}\pysiglinewithargsret{\strong{class }\code{distributions.}\bfcode{normal}}{\emph{mu}, \emph{sigma}}{}
The normal/Gaussian distribution is useful for everything
Parameters are mean, and the standard deviation

It is \(p(x\vert\mu ,\sigma) = \frac{ 1}{\sqrt{2\pi\sigma^2}}e^{\frac{-1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}\)

\end{fulllineitems}

\index{uniform (class in distributions)}

\begin{fulllineitems}
\phantomsection\label{code_distributions:distributions.uniform}\pysiglinewithargsret{\strong{class }\code{distributions.}\bfcode{uniform}}{\emph{a}, \emph{b}}{}
The uniform distribution is useful limiting ranges
Parameters are a (lower bound), and b (upper bound)

It is \(p(x\vert a , b) = \frac{1}{b-a}\)

\end{fulllineitems}



\subsection{Convert between distributions}
\label{code_distributions:convert-between-distributions}\index{convert\_distribution() (in module distributions)}

\begin{fulllineitems}
\phantomsection\label{code_distributions:distributions.convert_distribution}\pysiglinewithargsret{\code{distributions.}\bfcode{convert\_distribution}}{\emph{this}, \emph{to\_this\_type\_string}}{}
Converts \titleref{this} distribution to \titleref{to\_this\_type\_string} distribution
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{this} is a \titleref{biasd.distribution.\_distribution}

\item {} 
\titleref{to\_this\_type\_string} is a string of `beta', `gamma', `normal', or `uniform'

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
a \titleref{biasd.distribution.\_distribution}

\end{itemize}

\end{description}

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{biasd} \PYG{k+kn}{import} \PYG{n}{distributions} \PYG{k}{as} \PYG{n}{bd}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib.pyplot} \PYG{k+kn}{as} \PYG{n+nn}{plt}

\PYG{n}{n} \PYG{o}{=} \PYG{n}{bd}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{o}{.}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{o}{.}\PYG{l+m+mo}{01}\PYG{p}{)}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{10000}\PYG{p}{)}
\PYG{n}{c} \PYG{o}{=} \PYG{n}{bd}\PYG{o}{.}\PYG{n}{convert\PYGZus{}distribution}\PYG{p}{(}\PYG{n}{n}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{gamma}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{cc} \PYG{o}{=} \PYG{n}{bd}\PYG{o}{.}\PYG{n}{convert\PYGZus{}distribution}\PYG{p}{(}\PYG{n}{n}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{uniform}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{ccc} \PYG{o}{=} \PYG{n}{bd}\PYG{o}{.}\PYG{n}{convert\PYGZus{}distribution}\PYG{p}{(}\PYG{n}{n}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{beta}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{n}\PYG{o}{.}\PYG{n}{pdf}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{c}\PYG{o}{.}\PYG{n}{pdf}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{cc}\PYG{o}{.}\PYG{n}{pdf}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{ccc}\PYG{o}{.}\PYG{n}{pdf}\PYG{p}{(}\PYG{n}{x}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{yscale}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{log}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

\end{fulllineitems}



\subsection{Distributions can be collected for priors or posteriors}
\label{code_distributions:distributions-can-be-collected-for-priors-or-posteriors}\index{parameter\_collection (class in distributions)}

\begin{fulllineitems}
\phantomsection\label{code_distributions:distributions.parameter_collection}\pysiglinewithargsret{\strong{class }\code{distributions.}\bfcode{parameter\_collection}}{\emph{e1}, \emph{e2}, \emph{sigma}, \emph{k1}, \emph{k2}}{}
A collection of distribution functions that are used for the BIASD two-state model as parameters for Bayesian inference. parameter\_collection's are used as priors for BIASD.
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
e1 is the probability distribution for \(\epsilon_1\)

\item {} 
e2 is the probability distribution for \(\epsilon_2\)

\item {} 
sigma is the probability distribution for \(\sigma\)

\item {} 
k1 is the probability distribution for \(k_1\)

\item {} 
k2 is the probability distribution for \(k_2\)

\end{itemize}

\end{description}

\end{fulllineitems}



\subsection{Collections can be visualized}
\label{code_distributions:collections-can-be-visualized}\index{viewer (class in distributions)}

\begin{fulllineitems}
\phantomsection\label{code_distributions:distributions.viewer}\pysiglinewithargsret{\strong{class }\code{distributions.}\bfcode{viewer}}{\emph{data}}{}
Allows you to view BIASD parameter probability distributions
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
parameter\_collection is a biasd.distributions.parameter\_collection

\end{itemize}

\end{description}

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{biasd} \PYG{k+kn}{import} \PYG{n}{distributions} \PYG{k}{as} \PYG{n}{bd}

\PYG{c}{\PYGZsh{} Make the parameter\PYGZus{}collection}
\PYG{n}{e1} \PYG{o}{=} \PYG{n}{bd}\PYG{o}{.}\PYG{n}{normal}\PYG{p}{(}\PYG{l+m+mf}{5.}\PYG{p}{,}\PYG{l+m+mf}{1.}\PYG{p}{)}
\PYG{n}{e2} \PYG{o}{=} \PYG{n}{bd}\PYG{o}{.}\PYG{n}{beta}\PYG{p}{(}\PYG{l+m+mf}{95.}\PYG{p}{,}\PYG{l+m+mf}{5.}\PYG{p}{)}
\PYG{n}{sigma} \PYG{o}{=} \PYG{n}{bd}\PYG{o}{.}\PYG{n}{gamma}\PYG{p}{(}\PYG{l+m+mf}{5.}\PYG{p}{,}\PYG{l+m+mf}{100.}\PYG{p}{)}
\PYG{n}{k1} \PYG{o}{=} \PYG{n}{bd}\PYG{o}{.}\PYG{n}{gamma}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{,}\PYG{l+m+mf}{1.}\PYG{p}{)}
\PYG{n}{k2} \PYG{o}{=} \PYG{n}{bd}\PYG{o}{.}\PYG{n}{uniform}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mf}{1.}\PYG{p}{)}
\PYG{n}{d} \PYG{o}{=} \PYG{n}{bd}\PYG{o}{.}\PYG{n}{parameter\PYGZus{}collection}\PYG{p}{(}\PYG{n}{e1}\PYG{p}{,}\PYG{n}{e2}\PYG{p}{,}\PYG{n}{sigma}\PYG{p}{,}\PYG{n}{k1}\PYG{p}{,}\PYG{n}{k2}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Start the viewer}
\PYG{n}{v} \PYG{o}{=} \PYG{n}{bd}\PYG{o}{.}\PYG{n}{viewer}\PYG{p}{(}\PYG{n}{d}\PYG{p}{)}
\end{Verbatim}

\end{fulllineitems}



\subsection{Finally, you can easily generate a few useful collections using}
\label{code_distributions:module-distributions}\label{code_distributions:finally-you-can-easily-generate-a-few-useful-collections-using}\index{distributions (module)}\index{uninformative\_prior() (in module distributions)}

\begin{fulllineitems}
\phantomsection\label{code_distributions:distributions.uninformative_prior}\pysiglinewithargsret{\code{distributions.}\bfcode{uninformative\_prior}}{\emph{data\_range}, \emph{timescale}}{}
Generate an uninformative prior probability distribution for BIASD.
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{data\_range} is a list or array of the {[}lower,upper{]} bounds of the data

\item {} 
\titleref{timescale} is the frame rate (the prior will be centered here +/- 3 decades)

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
a flat \titleref{biasd.distributions.parameter\_collection}

\end{itemize}

\end{description}

\end{fulllineitems}

\index{guess\_prior() (in module distributions)}

\begin{fulllineitems}
\phantomsection\label{code_distributions:distributions.guess_prior}\pysiglinewithargsret{\code{distributions.}\bfcode{guess\_prior}}{\emph{y}, \emph{tau=1.0}}{}
Generate a guess for the prior probability distribution for BIASD. This approach uses a Gaussian mixture model to learn both states and the noise, then it idealizes the trace, and calculates the transition probabilities. Rate constants are then calculated, and an attempt is made to correct these with virtual states.
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{y} is a \titleref{numpy.ndarray} of the time series

\item {} 
\titleref{tau} is the measurement period of the time series (i.e., inverse acquisition rate)

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
a guessed \titleref{biasd.distributions.parameter\_collection}

\end{itemize}

\end{description}

\end{fulllineitems}



\section{Laplace}
\label{code_laplace::doc}\label{code_laplace:laplace}\label{code_laplace:code-laplace}
This page gives the details about the code in biasd.laplace.


\subsection{Laplace Approximation}
\label{code_laplace:laplace-approximation}
In order to calculate the Laplace approximation to the posterior probability distribution, you must calculate the second derivative of the log-posterior function at the maximum a posteriori (MAP) estimate. This module contains code to calculate the finite difference Hessian, find the MAP estimate of the BIASD log-posterior using numerical maximization (Nelder-Mead), and apply this analysis to a time series. You should probably only need to use the \titleref{biasd.laplace.laplace\_approximation()} function.
\phantomsection\label{code_laplace:module-laplace}\index{laplace (module)}\index{calc\_hessian() (in module laplace)}

\begin{fulllineitems}
\phantomsection\label{code_laplace:laplace.calc_hessian}\pysiglinewithargsret{\code{laplace.}\bfcode{calc\_hessian}}{\emph{fxn}, \emph{x}, \emph{eps=1.4901161193847656e-08}}{}
Calculate the Hessian using the finite difference approximation.

Finite difference formulas given in Abramowitz \& Stegun
\begin{itemize}
\item {} 
Eqn. 25.3.23 (on-diagonal)

\item {} 
Eqn. 25.3.26 (off-diagonal)

\end{itemize}
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{fxn} is a function that can be evaluated at x

\item {} 
\titleref{x} is a 1D \titleref{np.ndarray}

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
an NxN \titleref{np.ndarray}, where N is the size of \titleref{x}

\end{itemize}

\end{description}

\end{fulllineitems}

\index{find\_map() (in module laplace)}

\begin{fulllineitems}
\phantomsection\label{code_laplace:laplace.find_map}\pysiglinewithargsret{\code{laplace.}\bfcode{find\_map}}{\emph{data}, \emph{prior}, \emph{tau}, \emph{meth='nelder-mead'}, \emph{xx=None}, \emph{nrestarts=2}}{}
Use numerical minimization to find the maximum a posteriori estimate of a BIASD log-posterior distribution.
\begin{description}
\item[{Inputs:}] \leavevmode\begin{itemize}
\item {} 
\titleref{data} is a 1D \titleref{np.ndarray} of the time series

\item {} 
\titleref{prior} is a \titleref{biasd.distributions.parameter\_collection} that contains the prior the BIASD Bayesian inference

\item {} 
\titleref{tau} is the measurement period

\end{itemize}

\item[{Optional:}] \leavevmode\begin{itemize}
\item {} 
\titleref{meth} is the minimizer used to find the minimum of the negative posterior (i.e., the maximum). Defaults to simplex.

\item {} 
\titleref{xx} will initialize the minimizer at this theta position. Defaults to mean of the priors.

\item {} 
\titleref{nrestarts} is the number of times to try to find the minimum. Restarts initialize at a random variate chosen from prior distributions

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
the minimizer dictionary

\end{itemize}

\end{description}

\end{fulllineitems}

\index{laplace\_approximation() (in module laplace)}

\begin{fulllineitems}
\phantomsection\label{code_laplace:laplace.laplace_approximation}\pysiglinewithargsret{\code{laplace.}\bfcode{laplace\_approximation}}{\emph{data}, \emph{prior}, \emph{tau}, \emph{nrestarts=2}, \emph{verbose=False}}{}
Perform the Laplace approximation on the BIASD posterior probability distribution of this trace.
\begin{description}
\item[{Inputs:}] \leavevmode\begin{itemize}
\item {} 
\titleref{data} is a 1D \titleref{np.ndarray} of the time series

\item {} 
\titleref{prior} is a \titleref{biasd.distributions.parameter\_collection} that contains the prior the BIASD Bayesian inference

\item {} 
\titleref{tau} is the measurement period

\end{itemize}

\item[{Optional:}] \leavevmode\begin{itemize}
\item {} 
\titleref{nrestarts} is the number of times to try to find the MAP in \titleref{find\_map}.

\item {} 
\titleref{verbose} is a boolean that determines whether the evaluation time for each Hessian and minimization is printed.

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
a \titleref{biasd.laplace.\_laplace\_posterior} object, which has a \titleref{.mu} with the means, a \titleref{.covar} with the covariances, and a \titleref{.posterior} which is a marginalized \titleref{biasd.distributions.parameter\_collection} of normal distributions.

\end{itemize}

\end{description}

\end{fulllineitems}



\section{Likelihood}
\label{code_likelihood:code-likelihood}\label{code_likelihood:likelihood}\label{code_likelihood::doc}
This page gives the details about the code in biasd.likelihood.


\subsection{Switch the log-likelihood function}
\label{code_likelihood:switch-the-log-likelihood-function}
There are two main functions that you use for BIASD in \titleref{biasd.likelihood}. One to calculate the log-likelihood function, and the other to calculate the log-posterior function, which relies on the log-likelihood function. However, in truth, there are several different version of the log-likehood function that all accept the same arguments and return the results. There's one written in Python, (two) written in C, and one written in for CUDA. Assuming that they are compiled (i.e., C or CUDA), you can toggle between them to choose which version the log-likelihood function uses. In general, you'll want to use the C version if you have only a few data points (\textless{} 500), since it is fast and it allows you to use multiple processors when performing MCMC with emcee. If you have a lot of data points, you'll probably want to use the CUDA version, where each CUDA-core calculates the log-likelihood of a single data point. Anyway, you can toggle between the versions using

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{biasd} \PYG{k+kn}{as} \PYG{n+nn}{b}

\PYG{c}{\PYGZsh{} Switch to the slow, python implementation}
\PYG{n}{b}\PYG{o}{.}\PYG{n}{likelihood}\PYG{o}{.}\PYG{n}{use\PYGZus{}python\PYGZus{}ll}\PYG{p}{(}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Switch to the medium, parallelizable C version}
\PYG{n}{b}\PYG{o}{.}\PYG{n}{likelihood}\PYG{o}{.}\PYG{n}{use\PYGZus{}c\PYGZus{}ll}\PYG{p}{(}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Switch to the high\PYGZhy{}throughput CUDA version}
\PYG{n}{b}\PYG{o}{.}\PYG{n}{likelihood}\PYG{o}{.}\PYG{n}{use\PYGZus{}cuda\PYGZus{}ll}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

Finally, you can test the speed per datapoint of each of these version with
\index{test\_speed() (in module likelihood)}

\begin{fulllineitems}
\phantomsection\label{code_likelihood:likelihood.test_speed}\pysiglinewithargsret{\code{likelihood.}\bfcode{test\_speed}}{\emph{n}, \emph{dpoints=5000}}{}
Test how fast the BIASD integral runs.
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{n} is the number of times to repeat the test

\item {} 
\titleref{dpoints} is the number of data points in each test

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
The average amount of time per data point in seconds.

\end{itemize}

\end{description}

\end{fulllineitems}


If you're ever confused about which version you're using, you can check the \titleref{biasd.likelihood.ll\_version} variable.
\begin{description}
\item[{Warning:}] \leavevmode
Changing \titleref{biasd.likelihood.ll\_version} will not switch which likelihood function is being used.

\end{description}


\subsection{Inference-related functions}
\label{code_likelihood:module-likelihood}\label{code_likelihood:inference-related-functions}\index{likelihood (module)}\index{log\_likelihood() (in module likelihood)}

\begin{fulllineitems}
\phantomsection\label{code_likelihood:likelihood.log_likelihood}\pysiglinewithargsret{\code{likelihood.}\bfcode{log\_likelihood}}{\emph{theta}, \emph{data}, \emph{tau}}{}
Calculate the log of the BIASD likelihood function at \(\Theta\)
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{theta} is a \titleref{np.ndarray} of the parameters to evaluate

\item {} 
\titleref{data is a 1D {}`np.ndarray} of the time series to analyze

\item {} 
\titleref{tau} is the measurement period of each data point in \titleref{data}

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
the sum of the log-likelihood for each data point in \titleref{data}

\end{itemize}

\end{description}

\end{fulllineitems}

\index{log\_posterior() (in module likelihood)}

\begin{fulllineitems}
\phantomsection\label{code_likelihood:likelihood.log_posterior}\pysiglinewithargsret{\code{likelihood.}\bfcode{log\_posterior}}{\emph{theta}, \emph{data}, \emph{prior\_dists}, \emph{tau}}{}
Calculate the log-posterior probability distribution at \(\Theta\)
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{theta} is a vector of the parameters (i.e., \(\theta\)) where to evaluate the log-posterior

\item {} 
\titleref{data} is a 1D \titleref{np.ndarray} of the time series to analyze

\item {} 
\titleref{prior\_dists} is a \titleref{biasd.distributions.parameter\_collection} containing the prior probability distributions for the BIASD calculation

\item {} 
\titleref{tau} is the measurement period of \titleref{data}

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
The summed log posterior probability distribution, \(p(\Theta \vert data) \propto p(data \vert \Theta) \cdot p(\Theta)\)

\end{itemize}

\end{description}

\end{fulllineitems}



\section{MCMC}
\label{code_mcmc:code-mcmc}\label{code_mcmc::doc}\label{code_mcmc:mcmc}
This page gives the details about the code in biasd.mcmc.


\subsection{Markov chain Monte Carlo}
\label{code_mcmc:markov-chain-monte-carlo}
To sample the posterior probability distribution in BIASD, we'll use an affine invariant Markov chain Monte Carlo (MCMC) sampler. The implementation here uses \href{http://dan.iel.fm/emcee/current/}{emcee}, which allow very efficient MCMC sampling. It is described in
\begin{quote}\begin{description}
\item[{Title}] \leavevmode
emcee: The MCMC Hammer

\item[{Authors}] \leavevmode
Daniel Foreman-Mackey,
David W. Hogg,
Dustin Lang,
and Jonathan Goodman

\item[{arXiv}] \leavevmode
\url{http://arxiv.org/abs/1202.3665}

\item[{DOI}] \leavevmode
10.1086/670067

\end{description}\end{quote}

Which extends upon the paper
\begin{quote}\begin{description}
\item[{Title}] \leavevmode
Ensemble samplers with affine invariance

\item[{Authors}] \leavevmode
Jonathan Goodman,
and Jonathan Weare

\item[{Citation}] \leavevmode
\emph{Comm. Appl. Math. Comp. Sci.} \textbf{2010}, \emph{5(1)}, 65-80.

\item[{DOI}] \leavevmode
10.2140/camcos.2010.5.65\textgreater{}

\end{description}\end{quote}


\subsection{Setup and Run MCMC}
\label{code_mcmc:setup-and-run-mcmc}\label{code_mcmc:module-mcmc}\index{mcmc (module)}\phantomsection\label{code_mcmc:module-mcmc}\index{mcmc (module)}\index{setup() (in module mcmc)}

\begin{fulllineitems}
\phantomsection\label{code_mcmc:mcmc.setup}\pysiglinewithargsret{\code{mcmc.}\bfcode{setup}}{\emph{data}, \emph{priors}, \emph{tau}, \emph{nwalkers}, \emph{initialize='rvs'}, \emph{threads=1}}{}
Prepare the MCMC sampler
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{data} is a \titleref{np.ndarray} of the time series

\item {} 
\titleref{priors} is a \titleref{biasd.distributions.parameter\_collection} of the priors

\item {} 
\titleref{tau} is the measurement period each data point

\item {} 
\titleref{nwalkers} is the number of walkers in the MCMC ensemble. The more the better

\item {} \begin{description}
\item[{\titleref{initialze} =}] \leavevmode\begin{itemize}
\item {} 
`rvs' will initialize the walkers at a random spot chosen from the priors

\item {} 
`mean' will initialize the walkers tightly clustered around the mean of the priors.

\item {} 
an (\titleref{nwalkers},5) \titleref{np.ndarray} of whatever spots you want to initialize the walkers at.

\end{itemize}

\end{description}

\item {} 
\titleref{threads} is the number of threads to use for evaluating the log-posterior of the walkers. Be careful when using the CUDA log-likelihood function, because you'll probably be bottle-necked there.

\end{itemize}

\item[{Results:}] \leavevmode\begin{itemize}
\item {} 
An \titleref{emcee} sampler object. Please see the \titleref{emcee} documentation for more information.

\end{itemize}

\end{description}

\end{fulllineitems}

\index{burn\_in() (in module mcmc)}

\begin{fulllineitems}
\phantomsection\label{code_mcmc:mcmc.burn_in}\pysiglinewithargsret{\code{mcmc.}\bfcode{burn\_in}}{\emph{sampler}, \emph{positions}, \emph{nsteps=100}, \emph{timer=True}}{}
Burn-in will run some MCMC, getting new positions, and then reset the sampler so that nothing has been sampled.
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{sampler} is an \titleref{emcee} sampler

\item {} 
\titleref{positions} is the starting walker positions (maybe provided by \titleref{biasd.mcmc.setup}?)

\item {} 
\titleref{nsteps} is the integer number of MCMC steps to take

\item {} 
\titleref{timer} is a boolean for displaying the timing statistics

\end{itemize}

\item[{Results:}] \leavevmode\begin{itemize}
\item {} 
\titleref{sampler} is now a cleared \titleref{emcee} sampler where no steps have been made

\item {} 
\titleref{positions} is an array of the final walkers positions for use when starting a more randomized sampling

\end{itemize}

\end{description}

\end{fulllineitems}

\index{run() (in module mcmc)}

\begin{fulllineitems}
\phantomsection\label{code_mcmc:mcmc.run}\pysiglinewithargsret{\code{mcmc.}\bfcode{run}}{\emph{sampler}, \emph{positions}, \emph{nsteps}, \emph{timer=True}}{}
Acquire some MCMC samples, and keep them in the sampler
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{sampler} is an \titleref{emcee} sampler

\item {} 
\titleref{positions} is the starting walker positions (maybe provided by \titleref{biasd.mcmc.setup}?)

\item {} 
\titleref{nsteps} is the integer number of MCMC steps to take

\item {} 
\titleref{timer} is a boolean for displaying the timing statistics

\end{itemize}

\item[{Results:}] \leavevmode\begin{itemize}
\item {} 
\titleref{sampler} is the updated \titleref{emcee} sampler

\end{itemize}

\end{description}

\end{fulllineitems}

\index{continue\_run() (in module mcmc)}

\begin{fulllineitems}
\phantomsection\label{code_mcmc:mcmc.continue_run}\pysiglinewithargsret{\code{mcmc.}\bfcode{continue\_run}}{\emph{sampler}, \emph{nsteps}, \emph{timer=True}}{}
Similar to \titleref{biasd.mcmc.run}, but you do not need to specify the initial positions, because they will be the last sampled positions in \titleref{sampler}

\end{fulllineitems}


Example use:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{biasd} \PYG{k+kn}{as} \PYG{n+nn}{b}

\PYG{c}{\PYGZsh{} Load data}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{data.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{tau} \PYG{o}{=} \PYG{l+m+mf}{0.1}

\PYG{c}{\PYGZsh{} Get a molecule and priors}
\PYG{n}{d} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{values}\PYG{o}{.}\PYG{n}{FRET}
\PYG{n}{priors} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{guess\PYGZus{}priors}\PYG{p}{(}\PYG{n}{d}\PYG{p}{,}\PYG{n}{tau}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Setup the sampler for this molecule}
\PYG{c}{\PYGZsh{} Use 100 walkers, and 4 CPUs}
\PYG{n}{sampler}\PYG{p}{,} \PYG{n}{initial\PYGZus{}positions} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{setup}\PYG{p}{(}\PYG{n}{dy}\PYG{p}{,} \PYG{n}{priors}\PYG{p}{,} \PYG{n}{tau}\PYG{p}{,} \PYG{l+m+mi}{100}\PYG{p}{,} \PYG{n}{initialize}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{rvs}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{threads}\PYG{o}{=}\PYG{l+m+mi}{4}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Burn\PYGZhy{}in 100 steps and then remove them, but keep the final positions}
\PYG{n}{sampler}\PYG{p}{,}\PYG{n}{burned\PYGZus{}positions} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{burn\PYGZus{}in}\PYG{p}{(}\PYG{n}{sampler}\PYG{p}{,}\PYG{n}{initial\PYGZus{}positions}\PYG{p}{,}\PYG{n}{nsteps}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Run 100 steps starting at the burned\PYGZhy{}in positions.}
\PYG{n}{sampler} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{run}\PYG{p}{(}\PYG{n}{sampler}\PYG{p}{,}\PYG{n}{burned\PYGZus{}positions}\PYG{p}{,}\PYG{n}{nsteps}\PYG{o}{=}\PYG{l+m+mi}{100}\PYG{p}{)}
\PYG{c}{\PYGZsh{} Continue on from step 100 for another 900 steps. Don\PYGZsq{}t display timing}
\PYG{n}{sampler} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{continue\PYGZus{}run}\PYG{p}{(}\PYG{n}{sampler}\PYG{p}{,}\PYG{l+m+mi}{900}\PYG{p}{,}\PYG{n}{timer}\PYG{o}{=}\PYG{n+nb+bp}{False}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Save the sampler data}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{add}\PYG{o}{.}\PYG{n}{mcmc}\PYG{p}{(}\PYG{n}{sampler}\PYG{p}{)}
\PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{save}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{data.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{data}\PYG{p}{)}
\end{Verbatim}


\subsection{Analyze MCMC samples}
\label{code_mcmc:module-mcmc}\label{code_mcmc:analyze-mcmc-samples}\index{mcmc (module)}\phantomsection\label{code_mcmc:module-mcmc}\index{mcmc (module)}\index{chain\_statistics() (in module mcmc)}

\begin{fulllineitems}
\phantomsection\label{code_mcmc:mcmc.chain_statistics}\pysiglinewithargsret{\code{mcmc.}\bfcode{chain\_statistics}}{\emph{sampler}, \emph{verbose=True}}{}
Calculate the acceptance fraction and autocorrelation times of the samples in \titleref{sampler}

\end{fulllineitems}

\index{get\_samples() (in module mcmc)}

\begin{fulllineitems}
\phantomsection\label{code_mcmc:mcmc.get_samples}\pysiglinewithargsret{\code{mcmc.}\bfcode{get\_samples}}{\emph{sampler}, \emph{uncorrelated=True}, \emph{culled=True}}{}
Get the samples from \titleref{sampler}
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{sampler} is an \titleref{emcee} sampler with samples in it

\item {} 
\titleref{uncorrelated} is a boolean for whether to provide all the samples, or every n'th sample, where n is the larges autocorrelation time of the dimensions.

\item {} 
\titleref{culled} is a boolean, where any sample with a log-probability less than 0 is removed. This is necessary because sometimes a few chains get very stuck, and their samples (not being representative of the posterior) mess up subsequent plots.

\end{itemize}

\item[{Returns:}] \leavevmode
An (N,5) \titleref{np.ndarray} of samples from the sampler

\end{description}

\end{fulllineitems}

\index{plot\_corner() (in module mcmc)}

\begin{fulllineitems}
\phantomsection\label{code_mcmc:mcmc.plot_corner}\pysiglinewithargsret{\code{mcmc.}\bfcode{plot\_corner}}{\emph{samples}}{}
Use the python package called corner \textless{}\url{https://github.com/dfm/corner.py}\textgreater{} to make some very nice corner plots (joints and marginalized) of posterior in the 5-dimensions used by the two-state BIASD posterior.
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{samples} is a (N,5) \titleref{np.ndarray}

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
\titleref{fig} which is the handle to the figure containing the corner plot

\end{itemize}

\end{description}

\end{fulllineitems}

\index{create\_posterior\_collection() (in module mcmc)}

\begin{fulllineitems}
\phantomsection\label{code_mcmc:mcmc.create_posterior_collection}\pysiglinewithargsret{\code{mcmc.}\bfcode{create\_posterior\_collection}}{\emph{samples}, \emph{priors}}{}
Take the MCMC samples, marginalize them, and then calculate the first and second moments. Use these to moment-match to the types of distributions specified for each dimension in the priors. For instance, if the prior for \(\epsilon_1\) was beta distributed, this will moment-match the posterior to as a beta distribution.
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{samples} is a (N,5) \titleref{np.ndarray}

\item {} 
\titleref{priors} is a \titleref{biasd.distributions.parameter\_collection} that provides the distribution-forms to moment-match to

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
A \titleref{biasd.distributions.parameter\_collection} containing the marginalized, moment-matched posteriors

\end{itemize}

\end{description}

\end{fulllineitems}


Note, for the corner plot, you must have corner. Anyway, continuing on from the previous example...

Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c}{\PYGZsh{} ...}

\PYG{c}{\PYGZsh{} Calculate auto\PYGZhy{}correlation times for each variable}
\PYG{n}{largest\PYGZus{}autocorrelation\PYGZus{}time} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{chain\PYGZus{}statistics}\PYG{p}{(}\PYG{n}{sampler}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Collect uncorrelated samples from the sampler}
\PYG{n}{samples} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{get\PYGZus{}samples}\PYG{p}{(}\PYG{n}{sampler}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Plot the joint and marginalized distributions from the samples using corner, and then save the figure}
\PYG{n}{f} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{plot\PYGZus{}corner}\PYG{p}{(}\PYG{n}{samples}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{savefig}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{mcmc\PYGZus{}test.pdf}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Create a collection of the marginalized posterior distributions}
\PYG{n}{posterior} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{mcmc}\PYG{o}{.}\PYG{n}{create\PYGZus{}posterior\PYGZus{}collection}\PYG{p}{(}\PYG{n}{samples}\PYG{p}{,}\PYG{n}{priors}\PYG{p}{)}

\PYG{c}{\PYGZsh{} View that collection}
\PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{viewer}\PYG{p}{(}\PYG{n}{posterior}\PYG{p}{)}
\end{Verbatim}


\section{SMD}
\label{code_smd:code-smd}\label{code_smd:smd}\label{code_smd::doc}
This page gives the details about the code in biasd.smd.

The Single-Molecule Dataset (SMD) format is a standardized data format for use in time-resolved, single-molecule experiments (e.g, smFRET, force spectroscopy, etc.). It was published in collaboration between the \href{http://www.columbia.edu/cu/chemistry/groups/gonzalez/index.html}{Gonzalez} and \href{http://cmgm.stanford.edu/herschlag/}{Herschlag} labs (Greenfield, M \emph{et al}. \emph{BMC Bioinformatics} \textbf{2015}, \emph{16}, 3. \href{http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-014-0429-4}{DOI: 10.1186/s12859-014-0429-4}). A github page with some \href{https://smdata.github.io}{Matlab} and \href{https://github.com/smdata/smd-python}{Python} code exists.


\subsection{Work with SMD data}
\label{code_smd:work-with-smd-data}\label{code_smd:module-smd}\index{smd (module)}\index{new() (in module smd)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.new}\pysiglinewithargsret{\code{smd.}\bfcode{new}}{\emph{time}, \emph{data}, \emph{channel\_names=None}}{}
Create a new SMD structure. The structure is:
\begin{description}
\item[{SMD:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{.attr }] \leavevmode\begin{itemize}
\item {} 
.many

\item {} 
.items

\item {} 
.here

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{.data \code{(this is a list)}}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{{[}0{]} \code{(trace 0)}}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{.attr \code{(BIASD saves data in here)}}] \leavevmode\begin{itemize}
\item {} 
.many

\item {} 
.here

\end{itemize}

\end{description}

\item {} 
.id \code{(a unique number)}

\item {} 
.index \code{(time array)}

\item {} \begin{description}
\item[{.values \code{(signal data is in here)}}] \leavevmode\begin{itemize}
\item {} 
.channel\_1 \code{(e.g. Cy3)}

\item {} 
.channel\_2

\item {} 
.channel\_etc

\end{itemize}

\end{description}

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{{[}1{]} \code{(trace 1)}}] \leavevmode\begin{itemize}
\item {} 
...

\end{itemize}

\end{description}

\item {} 
...

\end{itemize}

\end{description}

\item {} \begin{description}
\item[{.id \code{(a unique number)}}] \leavevmode
\end{description}

\item {} \begin{description}
\item[{.types \code{(the datatypes of the entries in values)}}] \leavevmode
\end{description}

\end{itemize}

\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{time} is an \titleref{np.ndarray} of length T (number of datapoints). It marks the indexing time for each data point.

\item {} 
\titleref{data} is an NxDxT \titleref{np.ndarray}, because that ordering is consistent with original SMD...

\end{itemize}
\begin{description}
\item[{where: }] \leavevmode\begin{itemize}
\item {} 
N: number traces

\item {} 
D: data dimensionality i.e. number of channels

\item {} 
T: number of time points

\end{itemize}

\end{description}
\begin{itemize}
\item {} 
\titleref{channel\_names} is a list of strings, e.g. {[}''Cy3'',''Cy5''{]} of length D

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
an SMD object

\end{itemize}

\end{description}

\end{fulllineitems}

\index{load() (in module smd)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.load}\pysiglinewithargsret{\code{smd.}\bfcode{load}}{\emph{filename}, \emph{JSON=False}, \emph{conversion=\textless{}function \_conversion\_default\textgreater{}}}{}
Load an SMD file saved in JSON format into Python
Input:
\begin{itemize}
\item {} 
\titleref{filename} is a str with the path the SMD file you wish to open

\end{itemize}
\begin{description}
\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
SMD in Python object form

\end{itemize}

\end{description}

\end{fulllineitems}

\index{save() (in module smd)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.save}\pysiglinewithargsret{\code{smd.}\bfcode{save}}{\emph{filename}, \emph{smd}}{}
Save your SMD file. This has to save as JSON.... so all numpy things are turned into lists...
Input:
\begin{itemize}
\item {} 
\titleref{filename} is the output filename to save

\item {} 
\titleref{smd} is an SMD object that will be saved in \titleref{filename}

\end{itemize}

\end{fulllineitems}



\subsection{Add BIASD results to an SMD object}
\label{code_smd:module-smd.add}\label{code_smd:add-biasd-results-to-an-smd-object}\index{smd.add (module)}
Add a BIASD result to an SMD file. This includes functions for \titleref{prior collections}, \titleref{posterior collections}, \titleref{Laplace posteriors}, \titleref{baseline corrections}, and \titleref{MCMC results}.
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{smd} is the input SMD object where the data will be added

\item {} 
\titleref{i} is the number of the molecule to which to add the data

\item {} 
\titleref{final argument} is the data that will be added

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
\titleref{smd} is an updated SMD object

\end{itemize}

\end{description}
\index{baseline() (in module smd.add)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.add.baseline}\pysiglinewithargsret{\code{smd.add.}\bfcode{baseline}}{\emph{smd}, \emph{i}, \emph{p}}{}
Baseline result from biasd.utils.baseline

\end{fulllineitems}

\index{laplace\_posterior() (in module smd.add)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.add.laplace_posterior}\pysiglinewithargsret{\code{smd.add.}\bfcode{laplace\_posterior}}{\emph{smd}, \emph{i}, \emph{lp}}{}
Laplace posterior from biasd.laplace

\end{fulllineitems}

\index{mcmc() (in module smd.add)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.add.mcmc}\pysiglinewithargsret{\code{smd.add.}\bfcode{mcmc}}{\emph{smd}, \emph{i}, \emph{sampler}}{}
MCMC Result from biasd.mcmc

\end{fulllineitems}

\index{posterior() (in module smd.add)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.add.posterior}\pysiglinewithargsret{\code{smd.add.}\bfcode{posterior}}{\emph{smd}, \emph{i}, \emph{posterior}}{}
Posterior distribution collection from biasd.distributions

\end{fulllineitems}

\index{priors() (in module smd.add)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.add.priors}\pysiglinewithargsret{\code{smd.add.}\bfcode{priors}}{\emph{smd}, \emph{i}, \emph{priors}}{}
Piror distribution collection from biasd.distributions

\end{fulllineitems}



\subsection{Read BIASD results from an SMD object into a useful format}
\label{code_smd:read-biasd-results-from-an-smd-object-into-a-useful-format}\label{code_smd:module-smd.read}\index{smd.read (module)}
Read a BIASD result from an SMD file into a useful format. This includes functions for \titleref{prior collections}, \titleref{posterior collections}, \titleref{Laplace posteriors}, \titleref{baseline corrections}, and \titleref{MCMC results}.
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{smd} is the input SMD object from where the data will be read

\item {} 
\titleref{i} is the number of the molecule to from which to read the data

\end{itemize}

\end{description}
\index{baseline() (in module smd.read)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.read.baseline}\pysiglinewithargsret{\code{smd.read.}\bfcode{baseline}}{\emph{smd}, \emph{i}}{}
Load a baseline calculation from an SMD.
\begin{description}
\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
a \titleref{biasd.utils.baseline.params}

\end{itemize}

\end{description}

\end{fulllineitems}

\index{laplace\_posterior() (in module smd.read)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.read.laplace_posterior}\pysiglinewithargsret{\code{smd.read.}\bfcode{laplace\_posterior}}{\emph{smd}, \emph{i}}{}
Load a Laplace posterior object from an SMD.
\begin{description}
\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
a \titleref{biasd.laplace.\_laplace\_posterior}

\end{itemize}

\end{description}

\end{fulllineitems}

\index{mcmc() (in module smd.read)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.read.mcmc}\pysiglinewithargsret{\code{smd.read.}\bfcode{mcmc}}{\emph{smd}, \emph{i}}{}
Load a BIASD MCMC result from an SMD.
\begin{description}
\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
a \titleref{biasd.smd.read.mcmc.mcmc\_result}

\end{itemize}

\end{description}

\end{fulllineitems}

\index{posterior() (in module smd.read)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.read.posterior}\pysiglinewithargsret{\code{smd.read.}\bfcode{posterior}}{\emph{smd}, \emph{i}}{}
Load a BIASD posterior distribution collection from an SMD.
\begin{description}
\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
a \titleref{biasd.distributions.parameter\_collection}

\end{itemize}

\end{description}

\end{fulllineitems}

\index{priors() (in module smd.read)}

\begin{fulllineitems}
\phantomsection\label{code_smd:smd.read.priors}\pysiglinewithargsret{\code{smd.read.}\bfcode{priors}}{\emph{smd}, \emph{i}}{}
Load a BIASD prior distribution collection from an SMD.
\begin{description}
\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
a \titleref{biasd.distributions.parameter\_collection}

\end{itemize}

\end{description}

\end{fulllineitems}



\subsection{Examples}
\label{code_smd:examples}
Create, add, and save example

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{biasd} \PYG{k+kn}{as} \PYG{n+nn}{b}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}

\PYG{c}{\PYGZsh{} Load the data}
\PYG{n}{tau} \PYG{o}{=} \PYG{l+m+mf}{0.1}
\PYG{n}{t} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{1000}\PYG{p}{,}\PYG{n}{tau}\PYG{p}{)}
\PYG{n}{cy3} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{loadtxt}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{my\PYGZus{}cy3\PYGZus{}data.dat}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{cy5} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{loadtxt}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{my\PYGZus{}cy5\PYGZus{}data.dat}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{fret} \PYG{o}{=} \PYG{n}{d1}\PYG{o}{/}\PYG{p}{(}\PYG{n}{d1}\PYG{o}{+}\PYG{n}{d2}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Structure the data into NxDxT}
\PYG{n}{d} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{hstack}\PYG{p}{(}\PYG{p}{(}\PYG{n}{cy3}\PYG{p}{,}\PYG{n}{cy5}\PYG{p}{,}\PYG{n}{fret}\PYG{p}{)}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Make a new SMD}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{new}\PYG{p}{(}\PYG{n}{t}\PYG{p}{,}\PYG{n}{d}\PYG{p}{,}\PYG{p}{[}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Cy3}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Cy5}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{FRET}\PYG{l+s}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Setup the priors}
\PYG{n}{e1} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{beta}\PYG{p}{(}\PYG{l+m+mf}{1.}\PYG{p}{,}\PYG{l+m+mf}{9.}\PYG{p}{)}
\PYG{n}{e2} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{beta}\PYG{p}{(}\PYG{l+m+mf}{9.}\PYG{p}{,}\PYG{l+m+mf}{1.}\PYG{p}{)}
\PYG{n}{sigma} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{gamma}\PYG{p}{(}\PYG{l+m+mf}{2.}\PYG{p}{,}\PYG{l+m+mf}{2.}\PYG{o}{/}\PYG{o}{.}\PYG{l+m+mo}{05}\PYG{p}{)}
\PYG{n}{k1} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{gamma}\PYG{p}{(}\PYG{l+m+mf}{20.}\PYG{p}{,}\PYG{l+m+mf}{20.}\PYG{o}{/}\PYG{l+m+mf}{3.}\PYG{p}{)}
\PYG{n}{k2} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{gamma}\PYG{p}{(}\PYG{l+m+mf}{20.}\PYG{p}{,}\PYG{l+m+mf}{20.}\PYG{o}{/}\PYG{l+m+mf}{8.}\PYG{p}{)}
\PYG{n}{priors} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{distributions}\PYG{o}{.}\PYG{n}{parameter\PYGZus{}collection}\PYG{p}{(}\PYG{n}{e1}\PYG{p}{,}\PYG{n}{e2}\PYG{p}{,}\PYG{n}{sigma}\PYG{p}{,}\PYG{n}{k1}\PYG{p}{,}\PYG{n}{k2}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Loop over all the molecules}
\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{data}\PYG{o}{.}\PYG{n}{attr}\PYG{o}{.}\PYG{n}{n\PYGZus{}traces}\PYG{p}{)}\PYG{p}{:}

        \PYG{c}{\PYGZsh{} Add the priors, and Laplace posterior results}
        \PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{add\PYGZus{}priors}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{n}{i}\PYG{p}{,}\PYG{n}{priors}\PYG{p}{)}

        \PYG{c}{\PYGZsh{} Do a long calculations and add those results...}

        \PYG{c}{\PYGZsh{} Save the results as we go in case of a crash}
        \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{save}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{data.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{data}\PYG{p}{)}
\end{Verbatim}

Load, and read example

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{biasd} \PYG{k+kn}{as} \PYG{n+nn}{b}

\PYG{c}{\PYGZsh{} Load the SMD}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{data.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Read the priors for the first molecule (0)}
\PYG{n}{priors} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{read\PYGZus{}priors}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Read the Laplace posterior object for the first molecule (0)}
\PYG{n}{lp} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{read\PYGZus{}laplace\PYGZus{}posterior}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Read the MCMC rsults for the first molecule (0)}
\PYG{n}{mcmc\PYGZus{}results} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{read\PYGZus{}mcmc}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}
\end{Verbatim}


\section{Utils}
\label{code_utils:utils}\label{code_utils::doc}\label{code_utils:code-utils}
This page gives the details about the code in biasd.utils.


\subsection{Baseline Correction}
\label{code_utils:baseline-correction}
Code to correct for white-noise baseline drift. This type of drift will severely hinder the ability of BIASD to provide reasonable results.
\phantomsection\label{code_utils:module-utils.baseline}\index{utils.baseline (module)}\index{remove\_baseline() (in module utils.baseline)}

\begin{fulllineitems}
\phantomsection\label{code_utils:utils.baseline.remove_baseline}\pysiglinewithargsret{\code{utils.baseline.}\bfcode{remove\_baseline}}{\emph{d}, \emph{R2=None}, \emph{nstates=2}, \emph{maxiter=1000}, \emph{relative\_threshold=1e-20}}{}
Removes the baseline sort of according to:
\begin{quote}\begin{description}
\item[{Title}] \leavevmode
Automated Maximum Likelihood Separation of Signal from Baseline in Noisy Quantal Data

\item[{Authors}] \leavevmode
Bruno, WJ
Ullah, G
Mak, DD
Pearson JE

\item[{Citation}] \leavevmode
Biophys. J. 2013, 105, 68-79.

\end{description}\end{quote}
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{d} is a 1D array of the signal

\item {} 
\titleref{R2} can be an initial guess for the ratio of the random walk's variance to that of the noise variance of the underlying states.

\item {} 
\titleref{nstates} should probably be two for BIASD

\item {} 
\titleref{maxiter} the maximum number of times

\item {} 
\titleref{relative\_threshold} is the convergence threshold for the releative change in the log-likelihood function. Smaller values are more rigorous.

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
\titleref{baseline\_results} which is a \titleref{biasd.utils.baseline.params} object. You can access the baseline with \titleref{baseline\_results.basline}

\end{itemize}

\end{description}

\end{fulllineitems}


Example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib.pyplot} \PYG{k+kn}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{import} \PYG{n+nn}{biasd} \PYG{k+kn}{as} \PYG{n+nn}{b}

\PYG{c}{\PYGZsh{} Load some data}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{test.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{d} \PYG{o}{=} \PYG{n}{data}\PYG{o}{.}\PYG{n}{data}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{values}\PYG{o}{.}\PYG{n}{FRET}

\PYG{c}{\PYGZsh{} Calculate some fake baseline\PYGZhy{}drift and apply it to the data}
\PYG{n}{baseline} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{utils}\PYG{o}{.}\PYG{n}{baseline}\PYG{o}{.}\PYG{n}{simulate\PYGZus{}diffusion}\PYG{p}{(}\PYG{n}{d}\PYG{o}{.}\PYG{n}{size}\PYG{p}{,}\PYG{l+m+mf}{1e\PYGZhy{}2}\PYG{p}{)}
\PYG{n}{dd} \PYG{o}{=} \PYG{n}{d} \PYG{o}{+} \PYG{n}{baseline}

\PYG{c}{\PYGZsh{} Solve for the baseline}
\PYG{n}{baseline\PYGZus{}results} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{utils}\PYG{o}{.}\PYG{n}{baseline}\PYG{o}{.}\PYG{n}{remove\PYGZus{}baseline}\PYG{p}{(}\PYG{n}{dd}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Plot the results}
\PYG{n}{f}\PYG{p}{,}\PYG{n}{a} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{n}{sharex}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\PYG{n}{a}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{dd}\PYG{p}{,}\PYG{n}{color}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{b}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{a}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{baseline\PYGZus{}results}\PYG{o}{.}\PYG{n}{baseline}\PYG{p}{,}\PYG{n}{color}\PYG{o}{=}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{r}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{a}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{dd} \PYG{o}{\PYGZhy{}} \PYG{n}{baseline\PYGZus{}results}\PYG{o}{.}\PYG{n}{baseline}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{k}\PYG{l+s}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}

\PYG{c}{\PYGZsh{} Add the results to the SMD and save}
\PYG{n}{data} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{add}\PYG{o}{.}\PYG{n}{baseline}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{n}{baseline\PYGZus{}results}\PYG{p}{)}
\PYG{n}{b}\PYG{o}{.}\PYG{n}{smd}\PYG{o}{.}\PYG{n}{save}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{test.smd}\PYG{l+s}{\PYGZsq{}}\PYG{p}{,}\PYG{n}{data}\PYG{p}{)}
\end{Verbatim}


\subsection{Fit histograms to the BIASD likelihood function}
\label{code_utils:fit-histograms-to-the-biasd-likelihood-function}\begin{quote}

This might be useful for exploring data, or plotting.
\end{quote}
\phantomsection\label{code_utils:module-utils.fit_histogram}\index{utils.fit\_histogram (module)}\phantomsection\label{code_utils:module-fit_histogram}\index{fit\_histogram (module)}\index{fit() (in module utils.fit\_histogram)}

\begin{fulllineitems}
\phantomsection\label{code_utils:utils.fit_histogram.fit}\pysiglinewithargsret{\code{utils.fit\_histogram.}\bfcode{fit}}{\emph{data}, \emph{tau}, \emph{guess=None}}{}
Fits a histogram of to the BIASD likelihood function.

Input:
\begin{itemize}
\item {} 
\titleref{data} is a \titleref{np.ndarray}

\item {} 
\titleref{tau} is the measurement period

\item {} \begin{description}
\item[{\titleref{guess} is an initial guess. This can be provided as:}] \leavevmode\begin{itemize}
\item {} 
a \titleref{biasd.distributions.parameter\_collection}, it will use the mean

\item {} 
a \titleref{np.ndarray}

\item {} 
\titleref{Nothing...}, in which case it will try to guess

\end{itemize}

\end{description}

\end{itemize}
\begin{description}
\item[{Returns:}] \leavevmode\begin{itemize}
\item {} 
the best-fit parameters, and the covariances

\end{itemize}

\end{description}

\end{fulllineitems}

\index{likelihood\_one\_at\_a\_time() (in module utils.fit\_histogram)}

\begin{fulllineitems}
\phantomsection\label{code_utils:utils.fit_histogram.likelihood_one_at_a_time}\pysiglinewithargsret{\code{utils.fit\_histogram.}\bfcode{likelihood\_one\_at\_a\_time}}{\emph{theta}, \emph{data}, \emph{tau}}{}
Calculate the likelihood (not log-likelihood) for each point in a string of data. This might be useful for plotting, for instance:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{biasd} \PYG{k+kn}{as} \PYG{n+nn}{b}
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k+kn}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib.pyplot} \PYG{k+kn}{as} \PYG{n+nn}{plt}

\PYG{n}{theta} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mf}{0.}\PYG{p}{,}\PYG{l+m+mf}{1.}\PYG{p}{,}\PYG{o}{.}\PYG{l+m+mo}{05}\PYG{p}{,}\PYG{l+m+mf}{3.}\PYG{p}{,}\PYG{l+m+mf}{8.}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{x} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{linspace}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{o}{.}\PYG{l+m+mi}{5}\PYG{p}{,}\PYG{l+m+mf}{1.5}\PYG{p}{,}\PYG{l+m+mi}{1000}\PYG{p}{)}
\PYG{n}{y} \PYG{o}{=} \PYG{n}{b}\PYG{o}{.}\PYG{n}{utils}\PYG{o}{.}\PYG{n}{fit\PYGZus{}histogram}\PYG{o}{.}\PYG{n}{likelihood\PYGZus{}one\PYGZus{}at\PYGZus{}a\PYGZus{}time}\PYG{p}{(}\PYG{n}{theta}\PYG{p}{,}\PYG{n}{x}\PYG{p}{,}\PYG{l+m+mf}{0.1}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,}\PYG{n}{y}\PYG{p}{)}
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{show}\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

\end{fulllineitems}



\subsection{Clustering data}
\label{code_utils:clustering-data}
Here are some helper functions to perform clustering
\phantomsection\label{code_utils:module-utils.clustering}\index{utils.clustering (module)}\index{GMM\_EM\_1D() (in module utils.clustering)}

\begin{fulllineitems}
\phantomsection\label{code_utils:utils.clustering.GMM_EM_1D}\pysiglinewithargsret{\code{utils.clustering.}\bfcode{GMM\_EM\_1D}}{\emph{x}, \emph{k=2}, \emph{maxiter=1000}, \emph{relative\_threshold=1e-06}, \emph{init\_kmeans=True}}{}
One-dimensional, Gaussian Mixture Model Clustering with expectation-maximization algorithm.
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{x} is an (N,d) \titleref{np.array}, where N is the number of data points and d is the dimensionality of the data

\item {} 
\titleref{nstates} is the number of states

\item {} 
\titleref{maxiter} is the maximum number of iterations

\item {} 
\titleref{relative\_threshold} is the convergence criteria for the relative change in the log-likelihood

\item {} 
\titleref{init\_kmeans} is a boolean for whether to initialize the GMM with a K-means pass

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{a \titleref{biasd.utils.clustering.\_results\_gmm} object that contains}] \leavevmode\begin{itemize}
\item {} 
\titleref{pi\_k}, the probability of each state

\item {} 
\titleref{r\_nk}, the responsibilities of each data point

\item {} 
\titleref{mu\_k} the means

\item {} 
\titleref{var\_k} the covariances

\end{itemize}

\end{description}

\end{itemize}

\end{description}

\end{fulllineitems}

\index{kmeans() (in module utils.clustering)}

\begin{fulllineitems}
\phantomsection\label{code_utils:utils.clustering.kmeans}\pysiglinewithargsret{\code{utils.clustering.}\bfcode{kmeans}}{\emph{x}, \emph{nstates}, \emph{nrestarts=1}}{}
Multidimensional, K-means Clustering
\begin{description}
\item[{Input:}] \leavevmode\begin{itemize}
\item {} 
\titleref{x} is an (N,d) \titleref{np.array}, where N is the number of data points and d is the dimensionality of the data

\item {} 
\titleref{nstates} is the K in K-means

\item {} 
\titleref{nrestarts} is the number of times to restart. The minimal variance results are provided

\end{itemize}

\item[{Returns:}] \leavevmode\begin{itemize}
\item {} \begin{description}
\item[{a \titleref{biasd.utils.clustering.\_results\_kmeans} object that contains}] \leavevmode\begin{itemize}
\item {} 
\titleref{pi\_k}, the probability of each state

\item {} 
\titleref{r\_nk}, the responsibilities of each data point

\item {} 
\titleref{mu\_k} the means

\item {} 
\titleref{var\_k} the covariances

\end{itemize}

\end{description}

\end{itemize}

\end{description}

\end{fulllineitems}



\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{d}
\item {\texttt{distributions}}, \pageref{code_distributions:module-distributions}
\indexspace
\bigletter{f}
\item {\texttt{fit\_histogram}}, \pageref{code_utils:module-fit_histogram}
\indexspace
\bigletter{l}
\item {\texttt{laplace}}, \pageref{code_laplace:module-laplace}
\item {\texttt{likelihood}}, \pageref{code_likelihood:module-likelihood}
\indexspace
\bigletter{m}
\item {\texttt{mcmc}}, \pageref{code_mcmc:module-mcmc}
\indexspace
\bigletter{s}
\item {\texttt{smd}}, \pageref{code_smd:module-smd}
\item {\texttt{smd.add}}, \pageref{code_smd:module-smd.add}
\item {\texttt{smd.read}}, \pageref{code_smd:module-smd.read}
\indexspace
\bigletter{u}
\item {\texttt{utils.baseline}}, \pageref{code_utils:module-utils.baseline}
\item {\texttt{utils.clustering}}, \pageref{code_utils:module-utils.clustering}
\item {\texttt{utils.fit\_histogram}}, \pageref{code_utils:module-utils.fit_histogram}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
